{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hierarchical Graph Representation Learning with Differentiable Pooling\n",
    "\n",
    "<img src=\"static/diffpool.png\" alt=\"Diffpool\" width=\"800\" />\n",
    "\n",
    "Links to the original paper:\n",
    "* ArXiv: <https://arxiv.org/abs/1806.08804>\n",
    "* Code Repository: <https://github.com/RexYing/diffpool>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Toy Example: 1-Layer Diffpool\n",
    "\n",
    "In the following cells the mathematical formulas of Difffpool are explained with a small example.\n",
    "\n",
    "Consider a small graph with 5 nodes, 5 edges and each node has two features. In this example we use a one layer Diffpool model to reduce this graph to 2 clusters with new aggregated embeddings. As GNNs we use GraphSAGE for both the embedding and pooling models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import dgl\n",
    "\n",
    "from dgl_layers.model import DiffPool\n",
    "\n",
    "nx_G = nx.Graph()\n",
    "nx_G.add_edges_from([(1, 2), (2, 3), (3, 4), (3, 5), (4, 5)])\n",
    "\n",
    "g = dgl.from_networkx(nx_G)\n",
    "X = th.randn(5, 2)\n",
    "\n",
    "nx.draw(dgl.to_networkx(g))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compute cluster assignments & node embeddings\n",
    "\n",
    "The first step is to compute the cluster assignments and associated embeddings of the aggregated nodes. We simply apply the formulas provided in the paper:\n",
    "\n",
    "\\begin{align*}\n",
    "Z = \\mathrm{GNN}_{\\mathrm{embed}}(A, X) \\\\\n",
    "S = \\mathrm{softmax}(\\mathrm{GNN}_{\\mathrm{pool}}(A, X))\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.5802,  1.5725],\n",
       "         [-0.7592,  0.7675],\n",
       "         [ 0.5197, -0.5063],\n",
       "         [ 0.9098, -0.9169],\n",
       "         [ 0.9098, -0.9169]], grad_fn=<NativeBatchNormBackward0>),\n",
       " tensor([[0.5084, 0.4916],\n",
       "         [0.4933, 0.5067],\n",
       "         [0.4874, 0.5126],\n",
       "         [0.5055, 0.4945],\n",
       "         [0.5055, 0.4945]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dgl.nn.pytorch import DenseSAGEConv\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "embed = DenseSAGEConv(2, 2, norm=nn.BatchNorm1d(2))\n",
    "pool = DenseSAGEConv(2, 2, norm=nn.BatchNorm1d(2))\n",
    "\n",
    "A = g.adj().to_dense()\n",
    "Z = embed(A, X)\n",
    "S = softmax(pool(A, X), dim=-1)\n",
    "\n",
    "Z, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Construct the new representation graph\n",
    "\n",
    "In the second step we now have to construct the new graph. To do so, we first calculate the embeddings $X'$ for each cluster and then the new adjacency matrix $A'$ that connects the clusters.\n",
    "\n",
    "Again, we simply use the formulas from the paper in our example:\n",
    "\n",
    "\\begin{align*}\n",
    "X' = S^T Z \\\\\n",
    "A' = S^T A S\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0048,  0.0044],\n",
       "         [ 0.0048, -0.0044]], grad_fn=<MmBackward0>),\n",
       " tensor([[2.4788, 2.5002],\n",
       "         [2.5002, 2.5209]], grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = S.transpose(-1, -2) @ Z\n",
    "A_new = S.transpose(-1, -2) @ A @ S\n",
    "\n",
    "X_new, A_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we can take a look at the new graph. As already announced, we now have only two nodes that are connected by weighted edges and contain the embeddings from the nodes combined in them representatively in their new embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_new = nx.from_numpy_matrix(A_new.detach().numpy(), create_using=nx.Graph)\n",
    "g_new.remove_edges_from(nx.selfloop_edges(g_new))\n",
    "nx.draw(g_new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Diffpool in practice: Graph classification of the ENZYMES datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import tu\n",
    "import torch.utils.data\n",
    "\n",
    "dataset = tu.LegacyTUDataset(name=\"ENZYMES\")\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = int(0.1 * len(dataset))\n",
    "val_size = int(len(dataset) - train_size - test_size)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "dataset_train, dataset_val, dataset_test = torch.utils.data.random_split(\n",
    "    dataset, (train_size, val_size, test_size))\n",
    "train_dataloader = dgl.dataloading.GraphDataLoader(dataset_train, batch_size=batch_size)\n",
    "val_dataloader = dgl.dataloading.GraphDataLoader(dataset_val, batch_size=batch_size)\n",
    "test_dataloader = dgl.dataloading.GraphDataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "input_dim, label_dim, max_num_node = dataset.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "pool_ratio = 0.25\n",
    "\n",
    "assign_dim = int(max_num_node * pool_ratio)\n",
    "activation = F.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dgl_layers.model import DiffPool\n",
    "\n",
    "model = DiffPool(input_dim,\n",
    "                 hidden_dim,\n",
    "                 embedding_dim,\n",
    "                 label_dim,\n",
    "                 activation,\n",
    "                 3,\n",
    "                 0.0,\n",
    "                 1,\n",
    "                 True,\n",
    "                 20,\n",
    "                 'mean',\n",
    "                 assign_dim,\n",
    "                 pool_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate(dataloader, model):\n",
    "    model.eval()\n",
    "    correct_label = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_graph, graph_labels) in enumerate(dataloader):\n",
    "            for (key, value) in batch_graph.ndata.items():\n",
    "                batch_graph.ndata[key] = value.float()\n",
    "            graph_labels = graph_labels.long()\n",
    "            if torch.cuda.is_available():\n",
    "                batch_graph = batch_graph.to(torch.cuda.current_device())\n",
    "                graph_labels = graph_labels.cuda()\n",
    "            ypred = model(batch_graph)\n",
    "            indi = torch.argmax(ypred, dim=1)\n",
    "            correct = torch.sum(indi == graph_labels)\n",
    "            correct_label += correct.item()\n",
    "    result = correct_label / (len(dataloader) * 20)\n",
    "    return result\n",
    "\n",
    "def train(dataset, model, val_dataset=None):\n",
    "    dataloader = dataset\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                                        model.parameters()), lr=0.001)\n",
    "    early_stopping_logger = {\"best_epoch\": -1, \"val_acc\": -1}\n",
    "\n",
    "    for epoch in range(4000):\n",
    "        begin_time = time.time()\n",
    "        model.train()\n",
    "        accum_correct = 0\n",
    "        total = 0\n",
    "        print(\"\\nEPOCH ###### {} ######\".format(epoch))\n",
    "        computation_time = 0.0\n",
    "        for (batch_idx, (batch_graph, graph_labels)) in enumerate(dataloader):\n",
    "            for (key, value) in batch_graph.ndata.items():\n",
    "                batch_graph.ndata[key] = value.float()\n",
    "            graph_labels = graph_labels.long()\n",
    "            if torch.cuda.is_available():\n",
    "                batch_graph = batch_graph.to(torch.cuda.current_device())\n",
    "                graph_labels = graph_labels.cuda()\n",
    "\n",
    "            model.zero_grad()\n",
    "            compute_start = time.time()\n",
    "            ypred = model(batch_graph)\n",
    "            indi = torch.argmax(ypred, dim=1)\n",
    "            correct = torch.sum(indi == graph_labels).item()\n",
    "            accum_correct += correct\n",
    "            total += graph_labels.size()[0]\n",
    "            loss = model.loss(ypred, graph_labels)\n",
    "            loss.backward()\n",
    "            batch_compute_time = time.time() - compute_start\n",
    "            computation_time += batch_compute_time\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        train_accu = accum_correct / total\n",
    "        print(\"train accuracy for this epoch {} is {:.2f}%\".format(epoch,\n",
    "                                                               train_accu * 100))\n",
    "        elapsed_time = time.time() - begin_time\n",
    "        print(\"loss {:.4f} with epoch time {:.4f} s & computation time {:.4f} s \".format(\n",
    "            loss.item(), elapsed_time, computation_time))\n",
    "        if val_dataset is not None:\n",
    "            result = evaluate(val_dataset, model)\n",
    "            print(\"validation  accuracy {:.2f}%\".format(result * 100))\n",
    "            if early_stopping_logger['val_acc'] <= result <= train_accu:\n",
    "                early_stopping_logger.update(best_epoch=epoch, val_acc=result)\n",
    "            print(\"best epoch is EPOCH {}, val_acc is {:.2f}%\".format(early_stopping_logger['best_epoch'],\n",
    "                                                                  early_stopping_logger['val_acc'] * 100))\n",
    "        torch.cuda.empty_cache()\n",
    "    return early_stopping_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH ###### 0 ######\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DGLHeteroGraph' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m logger \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m result \u001B[38;5;241m=\u001B[39m evaluate(test_dataloader, model, logger)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest  accuracy \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(result \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m))\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(dataset, model, val_dataset)\u001B[0m\n\u001B[0;32m     42\u001B[0m model\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     43\u001B[0m compute_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 44\u001B[0m ypred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_graph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m indi \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(ypred, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     46\u001B[0m correct \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(indi \u001B[38;5;241m==\u001B[39m graph_labels)\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\diffpool-DLle-QNT-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Projects\\TUM\\master\\diffpool\\dgl_layers\\model.py:176\u001B[0m, in \u001B[0;36mDiffPool.forward\u001B[1;34m(self, g)\u001B[0m\n\u001B[0;32m    173\u001B[0m     readout \u001B[38;5;241m=\u001B[39m dgl\u001B[38;5;241m.\u001B[39mmax_nodes(g, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mh\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    174\u001B[0m     out_all\u001B[38;5;241m.\u001B[39mappend(readout)\n\u001B[1;32m--> 176\u001B[0m adj, h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfirst_diffpool_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg_embedding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    177\u001B[0m node_per_pool_graph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(adj\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(g\u001B[38;5;241m.\u001B[39mbatch_num_nodes()))\n\u001B[0;32m    179\u001B[0m h, adj \u001B[38;5;241m=\u001B[39m batch2tensor(adj, h, node_per_pool_graph)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\diffpool-DLle-QNT-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Projects\\TUM\\master\\diffpool\\dgl_layers\\gnn.py:35\u001B[0m, in \u001B[0;36mDiffPoolBatchedGraphLayer.forward\u001B[1;34m(self, g, h)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, g, h):\n\u001B[1;32m---> 35\u001B[0m     feat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeat_gc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# size = (sum_N, F_out), sum_N is num of nodes in this batch\u001B[39;00m\n\u001B[0;32m     36\u001B[0m     device \u001B[38;5;241m=\u001B[39m feat\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m     37\u001B[0m     assign_tensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool_gc(g, h)  \u001B[38;5;66;03m# size = (sum_N, N_a), N_a is num of nodes in pooled graph.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\diffpool-DLle-QNT-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\diffpool-DLle-QNT-py3.9\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\densesageconv.py:123\u001B[0m, in \u001B[0;36mDenseSAGEConv.forward\u001B[1;34m(self, adj, feat)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m     feat_src \u001B[38;5;241m=\u001B[39m feat_dst \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeat_drop(feat)\n\u001B[1;32m--> 123\u001B[0m adj \u001B[38;5;241m=\u001B[39m \u001B[43madj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m()\u001B[38;5;241m.\u001B[39mto(feat_src\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    124\u001B[0m in_degrees \u001B[38;5;241m=\u001B[39m adj\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    125\u001B[0m h_neigh \u001B[38;5;241m=\u001B[39m (adj \u001B[38;5;241m@\u001B[39m feat_src \u001B[38;5;241m+\u001B[39m feat_dst) \u001B[38;5;241m/\u001B[39m (in_degrees \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DGLHeteroGraph' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "logger = train(\n",
    "        train_dataloader,\n",
    "        model,\n",
    "        val_dataset=val_dataloader)\n",
    "result = evaluate(test_dataloader, model, logger)\n",
    "print(\"test  accuracy {:.2f}%\".format(result * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}